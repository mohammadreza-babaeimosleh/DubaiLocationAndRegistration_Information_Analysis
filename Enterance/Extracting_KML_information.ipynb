{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Mahrez_Enterance_Data/Data/\"\n",
        "kml_file = \"Dmgisnet_Enterances.kml\"\n",
        "\n",
        "# Define the KML namespace mapping\n",
        "ns = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
        "\n",
        "# Parse the KML file\n",
        "tree = ET.parse(os.path.join(DATA_DIR, kml_file))\n",
        "root = tree.getroot()\n",
        "\n",
        "# Prepare a list to hold the extracted data\n",
        "extracted_data = []\n",
        "\n",
        "# Iterate over all Placemark elements in the file\n",
        "for placemark in root.findall(\".//kml:Placemark\", ns):\n",
        "    # Find the SchemaData element that holds our target SimpleData elements\n",
        "    schema_data = placemark.find(\"kml:ExtendedData/kml:SchemaData\", ns)\n",
        "    if schema_data is None:\n",
        "        continue  # Skip if no schema data is found\n",
        "\n",
        "    # Extract each required field using the 'name' attribute\n",
        "    community = schema_data.find(\"kml:SimpleData[@name='COMMUNITY_']\", ns)\n",
        "    name_eng = schema_data.find(\"kml:SimpleData[@name='NAME_ENG']\", ns)\n",
        "    makani_num = schema_data.find(\"kml:SimpleData[@name='MAKANI_NUM']\", ns)\n",
        "    point_x = schema_data.find(\"kml:SimpleData[@name='POINT_X']\", ns)\n",
        "    point_y = schema_data.find(\"kml:SimpleData[@name='POINT_Y']\", ns)\n",
        "\n",
        "    # Get the coordinates from the Point element\n",
        "    coordinates = placemark.find(\"kml:Point/kml:coordinates\", ns)\n",
        "\n",
        "    # Retrieve text for each element (default to empty string if missing)\n",
        "    community_text = community.text if community is not None else \"\"\n",
        "    name_eng_text = name_eng.text if name_eng is not None else \"\"\n",
        "    makani_num_text = makani_num.text if makani_num is not None else \"\"\n",
        "    point_x_text = point_x.text if point_x is not None else \"\"\n",
        "    point_y_text = point_y.text if point_y is not None else \"\"\n",
        "    coordinates_text = coordinates.text.strip() if (coordinates is not None and coordinates.text) else \"\"\n",
        "\n",
        "    # Append the extracted values as a dictionary to our list\n",
        "    extracted_data.append({\n",
        "        \"NAME_ENG\": name_eng_text,\n",
        "        \"MAKANI_NUM\": makani_num_text,\n",
        "        \"POINT_X\": point_x_text,\n",
        "        \"POINT_Y\": point_y_text,\n",
        "        \"COMMUNITY_\": community_text,\n",
        "        \"coordinates\": coordinates_text\n",
        "    })\n",
        "\n",
        "# Define the output CSV file path in your Google Drive.\n",
        "csv_file = \"Dmgisnet_Enterances_extracted_data.csv\"\n",
        "csv_file_path = os.path.join(DATA_DIR, csv_file)\n",
        "\n",
        "# Write the extracted data to the CSV file.\n",
        "with open(csv_file_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "    fieldnames = [\"NAME_ENG\", \"MAKANI_NUM\", \"POINT_X\", \"POINT_Y\", \"COMMUNITY_\", \"coordinates\"]\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()  # Write column headers\n",
        "    for row in extracted_data:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(\"CSV file has been written to:\", csv_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-YGLsdeYnRE",
        "outputId": "1bed0cfa-0c47-4bbe-e821-1e68c9186b4c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "CSV file has been written to: /content/drive/MyDrive/Colab_Notebooks/Mahrez_Enterance_Data/Data/Dmgisnet_Enterances_extracted_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "len_df = len(df)\n",
        "print(\"Number of rows in the original DataFrame:\", len_df)\n",
        "\n",
        "# 1. Split the 'coordinates' column into three new columns: coordinate_x, coordinate_y, coordinate_z.\n",
        "#    We assume each value in 'coordinates' is like \"x,y,z\".\n",
        "coords = df['coordinates'].str.split(',', expand=True)\n",
        "df['coordinate_x'] = coords[0].str.strip()\n",
        "df['coordinate_y'] = coords[1].str.strip()\n",
        "df['coordinate_z'] = coords[2].str.strip()\n",
        "\n",
        "# 2. Process the 'MAKANI_NUM' column:\n",
        "#    - Check if the value is a string before splitting. If not, assign an empty list.\n",
        "#    - Strip any extra whitespace from each value.\n",
        "#    - Use explode() to create a separate row for each MAKANI_NUM instance.\n",
        "df['MAKANI_NUM'] = df['MAKANI_NUM'].apply(\n",
        "    lambda x: [num.strip() for num in x.split(',')] if isinstance(x, str) else []\n",
        ")\n",
        "df = df.explode('MAKANI_NUM')\n",
        "\n",
        "# Optionally, you can drop the original 'coordinates' column if it's no longer needed:\n",
        "# df.drop(columns=['coordinates'], inplace=True)\n",
        "\n",
        "modified_csv_file = 'Dmgisnet_Enterances_extracted_data_modified.csv'\n",
        "modified_csv_file_path = os.path.join(DATA_DIR, modified_csv_file)\n",
        "df.to_csv(modified_csv_file_path, index=False)\n",
        "\n",
        "len_df = len(df)\n",
        "print(\"Number of rows in the new DataFrame:\", len_df)\n",
        "print(\"CSV file has been written to:\", modified_csv_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xICY9zPcxwjS",
        "outputId": "4f7baa44-5f34-4151-9c0f-c18bae77b5f5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the original DataFrame: 70142\n",
            "Number of rows in the new DataFrame: 108289\n",
            "CSV file has been written to: /content/drive/MyDrive/Colab_Notebooks/Mahrez_Enterance_Data/Data/Dmgisnet_Enterances_extracted_data_modified.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyHU6QlC2z56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}